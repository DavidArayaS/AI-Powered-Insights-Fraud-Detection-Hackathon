# ğŸ“– Solution to challenge 2: Automating Document Processing with Logic Apps  

## ğŸ”¹ Objective  

In this challenge, you will:  

âœ… Set up an Azure Logic App to process PDFs automatically  
âœ… Enable Managed Identity and Assign Permissions to the Logic App  
âœ… Use Document Intelligence (Form Recognizer) to analyze financial PDFs  
âœ… Create an ADF pipeline to move PDFs from Fabric to a Storage Account  
âœ… Store analyzed JSON outputs in Storage Account  
âœ… Verify that all processed files are saved in JSON format in Storage Account  

---

## ğŸš€ Step 1: Create a Logic App  

### 1ï¸âƒ£ Create a Logic App  
- Open **Azure Portal**  
- Search for **Logic Apps** â†’ Click **+ Create**  
- Fill in the details:  
  - **Resource Group**: `YourUniqueResourceGroup`  
  - **Use the same region for all the resources you deployed already**
  - **Name**: `YourLogicApp`  
  - **Plan Type**: `Consumption`  
- Click **Review + Create** â†’ **Create**  

---

## ğŸš€ Step 2: Enable Managed Identity for the Logic App  

### 1ï¸âƒ£ Activate System-Assigned Managed Identity  
- Go to **YourLogicApp**  
- Click **Identity** (Left Menu)  
- Enable **System Assigned Identity**  
- Click **Save**  
- Copy the **Object (Principal) ID**  

âœ… **Outcome**: The Logic App has an identity for authentication.  

---

## ğŸš€ Step 3: Assign Logic App Permissions  

- Go to your **Storage Account** **Storage Account** and **Document Intelligence** â†’ Click **Access Control (IAM)**  
- Click **Add Role Assignment**  
- Assign the following roles to the **Logic App Managed Identity**:  
  âœ… **Storage Blob Data Contributor**  
  âœ… **Storage Account Contributor**  
  âœ… **Cognitive Services Contributor** (For Document Intelligence)  

âœ… **Outcome**: The Logic App can read PDFs from Azure Blob Storage and write analyzed JSONs to Storage Account.  

---

## ğŸš€ Step 4: Configure the Logic App in the Azure Portal (Designer)  

- Open **YourLogicApp** â†’ Click **Logic App Designer**  
- Click **Blank Logic App**  
- Click **+ Add Trigger** â†’ Search for **Azure Blob Storage**  
- Select **When a blob is added or modified (properties only)**  
  - **Storage Account**: `Your Storage Account`  
  - **Container Name**: `incoming-docs`  
  - **Trigger Conditions**: `Ends with .pdf`  
  - **Interval**: `1 Minute`  

- Click **+ Add Step** â†’ Search for **Document Intelligence (Form Recognizer)**  
- Select **Analyze Document (Prebuilt-Invoice)**  
  - **Storage URL**:  
    ```plaintext
    https://yourstoragename.blob.core.windows.net/incoming-docs/@{triggerOutputs()?['body']['name']}
    ```  

- Click **+ Add Step** â†’ Search for **Azure Blob Storage**  
- Select **Create Blob**  
  - **Storage Account**: `Your Storage Account`  
  - **Container Name**: `processed-json`  
  - **Blob Name**:  
    ```plaintext
    analyzed-document-@{triggerOutputs()?['body']['name']}.json
    ```  
  - **Blob Content**:  
    ```plaintext
    @body('Analyze_Document_for_Prebuilt_or_Custom_models_(v4.x_API)')
    ```  
- Click **Save**  

âœ… **Outcome**: The Logic App automatically analyzes PDFs and saves JSON outputs in Storage Account.  

---

## ğŸš€ Step 5: (Alternative) Use JSON Code for the Logic App  

If you want a faster approach, paste the following JSON into the **Logic App Code Editor** (modify as needed):  

[LogicApp.json]()

âœ… Outcome: The Logic App will process PDFs and save JSONs without using the Designer.

---
## ğŸš€ Step 6: Create an Azure Data Factory (ADF)  

### 1ï¸âƒ£ Create an ADF Instance  
- Open **Azure Portal** â†’ Search for **Data Factory**  
- Click **+ Create**  
- Fill in the details:  
  - **Subscription**: Select your subscription  
  - **Resource Group**: `YourUniqueResourceGroup`  
  - **Region**: Same as Fabric  
  - **Name**: `YourADFInstance`  
- Click **Review + Create** â†’ Click **Create**  

âœ… **Outcome**: The ADF instance is created.  

---

## ğŸš€ Step 7: Create the ADF Copy Pipeline  

- Open **Azure Data Factory** â†’ Click **Author & Monitor**  
- Click **+ New Pipeline**  
- Click **+ Add Activity** â†’ Select **Copy Data**  

### ğŸ”¹ Configure the Source (Fabric Lakehouse)  
- Click **Source Tab** â†’ Click **+ New**  
- Select **Microsoft Fabric Lakehouse Files**  
- **Linked Service**: Create a new Linked Service if needed  
- **Authentication**: `Service Principal`  
- Provide **Tenant ID, Client ID, Client Secret**  
- **Select Folder Path**: `/Files/`  
- Click **Save**  

### ğŸ”¹ Configure the Destination (Azure Blob Storage)  
- Click **Sink Tab** â†’ Click **+ New**  
- Select **Azure Blob Storage**  
- **Container**: `Your Container`  
- Click **Save**  

### ğŸ”¹ Run the Pipeline  
- Click **Validate** â†’ Ensure no errors  
- Click **Trigger Now**  
- Click *Publish*

âœ… **Outcome**: PDFs are moved from Fabric to Azure Storage, triggering the Logic App.  

---

## ğŸš€ Step 8: Verify Processed JSON Files in Storage Account  

- Open **Azure Portal** â†’ Go to **YourStorage AccountAccount**  
- Open `processed-json` â†’ Verify JSON files  

âœ… **Final Outcome**: Processed documents are saved in Storage Account for fraud detection! ğŸš€ğŸ”¥  

## ğŸš€ Step 9: Create a new Fabric Lakehouse for the Analyzed JSON data

- Open Fabric â†’ Click **Your Worskpace**  
- Click **+ New Item** 
- Select and Create a new **Lakehouse** for your analyzed data to be use in future stages of the solution you are building.  


## ğŸ¯ Step 10: Challenge!!

- Look for a way to get your analyzed JSON data into the new Lakehouse in Microsoft Fabric

### ğŸ”¹ Hints:  
- Logic App
- Fabric Copy Pipeline
- ADF Pipeline
- Manual Upload

---